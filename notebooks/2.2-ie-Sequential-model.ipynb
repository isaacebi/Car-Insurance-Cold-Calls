{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77c5f7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectPercentile, f_classif, chi2\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "MODELS_PATH = os.path.join(PROJECT_DIR, 'models')\n",
    "ENCODER_PATH = os.path.join(MODELS_PATH, 'encoders')\n",
    "TEST_DATA_PATH = os.path.join(PROJECT_DIR, \n",
    "                              'data', 'raw', 'carInsurance_train.csv')\n",
    "\n",
    "CATEG_PATH = os.path.join(PROJECT_DIR, 'references', 'categorical_columns.txt')\n",
    "CONTI_PATH = os.path.join(PROJECT_DIR, 'references', 'continous_columns.txt')\n",
    "\n",
    "PROJECT_NAME = '2.1-ie-Linear-SVC-model'\n",
    "MODEL_NAME = 'LinearSVC-v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a14e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding system path\n",
    "sys.path.insert(0, PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal function\n",
    "from src.data import process_pipeline, encoder_pipeline, feature_selection_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helper Function\n",
    "def get_content(txt_file):\n",
    "    contents = []\n",
    "    with open(txt_file) as file:\n",
    "        for line in file:\n",
    "            contents.append(line.strip())\n",
    "            \n",
    "    return contents\n",
    "\n",
    "# Function to save a trained model\n",
    "def save_model(model, model_name, folderPath):\n",
    "    filename = os.path.join(folderPath, f\"{model_name}_model.pkl\")\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "# Function to load a saved model\n",
    "def load_model(model_name):\n",
    "    filename = f\"{model_name}_model.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, model_name, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557da9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TEST_DATA_PATH)\n",
    "df = process_pipeline.process_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical & continous variable\n",
    "categ = get_content(CATEG_PATH)\n",
    "conti = get_content(CONTI_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037816c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "X = df.drop(columns=['CarInsurance'])\n",
    "\n",
    "#target\n",
    "y = df['CarInsurance']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Function to select non-datetime columns\n",
    "def select_non_datetime(X):\n",
    "    return X.select_dtypes(exclude='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric feature processing\n",
    "numeric_filter = SelectPercentile(f_classif, percentile=50)\n",
    "numeric_transformer = make_pipeline(\n",
    "    FunctionTransformer(select_non_datetime, validate=False), \n",
    "    numeric_filter\n",
    ")\n",
    "\n",
    "# Categorical feature processing\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "categorical_filter = SelectPercentile(chi2, percentile=50)\n",
    "categorical_transformer = make_pipeline(ordinal_encoder, categorical_filter)\n",
    "\n",
    "# combine pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, conti),\n",
    "        (\"cat\", categorical_transformer, categ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a dictionary to store model performances\n",
    "# model_performances = {}\n",
    "\n",
    "# # Model 1: SVC\n",
    "# clf = LinearSVC(\n",
    "#     dual='auto'\n",
    "# )\n",
    "# pipeline_clf = make_pipeline(preprocessor, clf)\n",
    "\n",
    "# # Hyperparameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'linearsvc__C': [0.1, 1, 10],\n",
    "#     'linearsvc__multi_class': ['ovr', 'crammer_singer'],\n",
    "#     'linearsvc__intercept_scaling': [1, 2, 3]\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV for SVC\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline_clf, \n",
    "#     param_grid, \n",
    "#     cv=5, \n",
    "#     scoring='accuracy',\n",
    "#     error_score='raise',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Save the trained model\n",
    "# save_model(grid_search, MODEL_NAME, MODELS_PATH)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# accuracy = evaluate_model(grid_search, 'LinearSVC', X_test, y_test)\n",
    "\n",
    "# # Track the performance in the dictionary\n",
    "# model_performances['LinearSVC'] = {\n",
    "#     'best_params': grid_search.best_params_,\n",
    "#     'best_accuracy': grid_search.best_score_,\n",
    "#     'test_accuracy': accuracy\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93500368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
