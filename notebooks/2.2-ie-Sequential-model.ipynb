{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f77c5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d56aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "MODELS_PATH = os.path.join(PROJECT_DIR, 'models')\n",
    "ENCODER_PATH = os.path.join(MODELS_PATH, 'encoders')\n",
    "LOGS_PATH = os.path.join(MODELS_PATH, 'logs')\n",
    "TEST_DATA_PATH = os.path.join(PROJECT_DIR, \n",
    "                              'data', 'raw', 'carInsurance_train.csv')\n",
    "\n",
    "CATEG_PATH = os.path.join(PROJECT_DIR, 'references', 'categorical_columns.txt')\n",
    "CONTI_PATH = os.path.join(PROJECT_DIR, 'references', 'continous_columns.txt')\n",
    "\n",
    "PROJECT_NAME = '2.1-ie-Linear-SVC-model'\n",
    "MODEL_NAME = 'LinearSVC-v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74a14e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding system path\n",
    "sys.path.insert(0, PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68e907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal function\n",
    "from src.data import process_pipeline, encoder_pipeline, feature_selection_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e75bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helper Function\n",
    "def get_content(txt_file):\n",
    "    contents = []\n",
    "    with open(txt_file) as file:\n",
    "        for line in file:\n",
    "            contents.append(line.strip())\n",
    "            \n",
    "    return contents\n",
    "\n",
    "# Function to save a trained model\n",
    "def save_model(model, model_name, folderPath):\n",
    "    filename = os.path.join(folderPath, f\"{model_name}_model.pkl\")\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "# Function to load a saved model\n",
    "def load_model(model_name):\n",
    "    filename = f\"{model_name}_model.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, model_name, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "557da9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default</th>\n",
       "      <th>Balance</th>\n",
       "      <th>HHInsurance</th>\n",
       "      <th>CarLoan</th>\n",
       "      <th>Communication</th>\n",
       "      <th>LastContactDay</th>\n",
       "      <th>LastContactMonth</th>\n",
       "      <th>NoOfContacts</th>\n",
       "      <th>DaysPassed</th>\n",
       "      <th>PrevAttempts</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>CallStart</th>\n",
       "      <th>CallEnd</th>\n",
       "      <th>CarInsurance</th>\n",
       "      <th>CallDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>1218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>jan</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 13:45:20</td>\n",
       "      <td>1900-01-01 13:46:30</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>may</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 14:49:03</td>\n",
       "      <td>1900-01-01 14:52:08</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 16:30:24</td>\n",
       "      <td>1900-01-01 16:36:04</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>primary</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:06:43</td>\n",
       "      <td>1900-01-01 12:20:22</td>\n",
       "      <td>1</td>\n",
       "      <td>819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>2694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 14:35:44</td>\n",
       "      <td>1900-01-01 14:38:56</td>\n",
       "      <td>0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Age          Job  Marital Education  Default  Balance  HHInsurance  \\\n",
       "0   1   32   management   single  tertiary        0     1218            1   \n",
       "1   2   32  blue-collar  married   primary        0     1156            1   \n",
       "2   3   29   management   single  tertiary        0      637            1   \n",
       "3   4   25      student   single   primary        0      373            1   \n",
       "4   5   30   management  married  tertiary        0     2694            0   \n",
       "\n",
       "   CarLoan  Communication  LastContactDay LastContactMonth  NoOfContacts  \\\n",
       "0        0              1              28              jan             2   \n",
       "1        0              0              26              may             5   \n",
       "2        0              1               3              jun             1   \n",
       "3        0              1              11              may             2   \n",
       "4        0              1               3              jun             1   \n",
       "\n",
       "   DaysPassed  PrevAttempts  Outcome           CallStart             CallEnd  \\\n",
       "0          -1             0        0 1900-01-01 13:45:20 1900-01-01 13:46:30   \n",
       "1          -1             0        0 1900-01-01 14:49:03 1900-01-01 14:52:08   \n",
       "2         119             1        0 1900-01-01 16:30:24 1900-01-01 16:36:04   \n",
       "3          -1             0        0 1900-01-01 12:06:43 1900-01-01 12:20:22   \n",
       "4          -1             0        0 1900-01-01 14:35:44 1900-01-01 14:38:56   \n",
       "\n",
       "   CarInsurance  CallDuration  \n",
       "0             0          70.0  \n",
       "1             0         185.0  \n",
       "2             1         340.0  \n",
       "3             1         819.0  \n",
       "4             0         192.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TEST_DATA_PATH)\n",
    "df = process_pipeline.process_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b822693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical & continous variable\n",
    "categ = get_content(CATEG_PATH)\n",
    "conti = get_content(CONTI_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "037816c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# label\n",
    "X = df.drop(columns=['CarInsurance'])\n",
    "\n",
    "#target\n",
    "y = df['CarInsurance']\n",
    "\n",
    "# Target Encoding\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = ohe.fit_transform(np.expand_dims(y, axis=-1))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ff5f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Function to select non-datetime columns\n",
    "def select_non_datetime(X):\n",
    "    return X.select_dtypes(exclude='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b76a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric feature processing\n",
    "numeric_transformer = make_pipeline(\n",
    "    FunctionTransformer(select_non_datetime, validate=False)\n",
    ")\n",
    "\n",
    "# Categorical feature processing\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "categorical_transformer = make_pipeline(ordinal_encoder)\n",
    "\n",
    "# combine pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, conti),\n",
    "        (\"cat\", categorical_transformer, categ)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8a8d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a input and output shape\n",
    "input_shape = np.shape(X_train)[1:]\n",
    "model_output = len(np.unique(y_train, axis=0)) # alternative len(df.target.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86b12fec-b1ba-44a8-8faf-a52a4041c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, model_output):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(model_output, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d522697b-0356-499a-9965-4892e884b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call backs\n",
    "def callbacks(LOGS_PATH, patience):\n",
    "    tensorboard_callbacks = TensorBoard(log_dir=LOGS_PATH, histogram_freq=1)\n",
    "    early_callback = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    return [early_callback, tensorboard_callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b40ce75-4157-4e44-a80a-77d0cafec8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_13336\\222994273.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  clf = KerasClassifier(build_fn=lambda : create_model(input_shape, model_output), verbose=0)\n"
     ]
    }
   ],
   "source": [
    "clf = KerasClassifier(build_fn=lambda : create_model(input_shape, model_output), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d2237d1-6431-4dfe-9272-99dfb77b949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                1280      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,810\n",
      "Trainable params: 3,618\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.build_fn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebf226be-422c-4abc-bce7-5cec4aa2eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52378c1f-c08c-4a6b-b8ee-28ad1e50817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_callback, tensorboard_callbacks = callbacks(LOGS_PATH, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad3724ed-c9da-41cd-9ae7-2f686991a825",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 19), found shape=(32, 16)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[0;32m    173\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 175\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileb9t71o4o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\isaac\\anaconda3\\envs\\ds_project\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 19), found shape=(32, 16)\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185fdb5-8c03-4e57-af2c-97936a32a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
